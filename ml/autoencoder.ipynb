{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from autoencoder import AutoEncoder, VariationalAutoEncoder, LSTMAutoEncoder\n",
    "import resources\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import PurePosixPath as Path\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in RMS data for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exps = ['Test 5', 'Test 7', 'Test 8', 'Test 9']\n",
    "exps = ['Test 5']\n",
    "rms = {}\n",
    "\n",
    "for test in exps:\n",
    "    rms[test] = resources.ae.RMS(test)\n",
    "    rms[test].data.drop(['0', '1', '2',], axis=1, inplace=True)\n",
    "    \n",
    "try:\n",
    "    rms['Test 5'].data.drop(['23', '24'], axis=1, inplace=True)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dc(sig):\n",
    "    return sig - np.nanmean(sig)\n",
    "\n",
    "for test in exps:\n",
    "    rms[test]._data = rms[test].data.iloc[50:350, :].reset_index(drop=True)\n",
    "    rms[test]._data = rms[test].data.apply(remove_dc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rms[test].data.values\n",
    "r.shape\n",
    "plt.plot(r[:, 43])\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Rolling RMS (V)')\n",
    "plt.autoscale(enable=True, axis='x', tight=True)\n",
    "# plt.plot(r[:, 120])\n",
    "# plt.plot(r[:, 145])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Variational Autoencoder for each Test\n",
    "- The model is trained over a small section of the test depending on `train_slice`.\n",
    "- The model parameters are specified within the `params` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoe = {}\n",
    "for test in exps:\n",
    "        \"\"\"\n",
    "        autoe[test] = VariationalAutoEncoder(rms[test],\n",
    "                                             rms[test].data,\n",
    "                                             tb=False,\n",
    "                                             tb_logdir=rms[test].exp_name,\n",
    "                                             train_slice=(0, 75),\n",
    "                                             val_frac=0.33,\n",
    "                                             params={'latent_dim': 4,\n",
    "                                                   'n_size': [64, 32],\n",
    "                                                   'epochs': 1000,\n",
    "                                                   'batch_size': 15,\n",
    "                                                   'callbacks': [\n",
    "                                                           tf.keras.callbacks.EarlyStopping(\n",
    "                                                                monitor='val_loss',\n",
    "                                                                patience=60,\n",
    "                                                                mode='min',\n",
    "                                                                start_from_epoch=100,\n",
    "                                                           ),\n",
    "                                                        ]\n",
    "                                                   }\n",
    "                                           )\n",
    "        \"\"\"\n",
    "        '''\n",
    "        autoe[test] = AutoEncoder(rms[test],\n",
    "                                  rms[test].data,\n",
    "                                  tb=False,\n",
    "                                  tb_logdir=rms[test].exp_name.upper().replace(' ', '_'),\n",
    "                                  train_slice=(0, 50),\n",
    "                                  val_frac=0.33,\n",
    "                                  random_state=2,\n",
    "                                  params={'n_bottleneck': 9,\n",
    "                                          'n_size': [42, 32, 16],\n",
    "                                          'epochs': 1000,\n",
    "                                          'batch_size': 40,\n",
    "                                          'loss': 'mse',\n",
    "                                          'callbacks': [\n",
    "                                                  tf.keras.callbacks.EarlyStopping(\n",
    "                                                              monitor='val_loss',\n",
    "                                                              patience=80,\n",
    "                                                              mode='min',\n",
    "                                                              start_from_epoch= 150,\n",
    "                                                  ),\n",
    "                                                #   tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                                #                 monitor='val_loss',\n",
    "                                                #                 mode='min',\n",
    "                                                #                 patience=25,\n",
    "                                                #                 factor=0.01,\n",
    "                                                #   ),\n",
    "                                                ]\n",
    "\n",
    "                                          }\n",
    "                                  )                                \n",
    "        '''\n",
    "        autoe[test] = LSTMAutoEncoder(rms[test],\n",
    "                                      rms[test].data,\n",
    "                                      tb=False,\n",
    "                                      tb_logdir='LSTMAE_test',\n",
    "                                      train_slice=(0, 60),\n",
    "                                      val_frac=0.33,\n",
    "                                      params={'epochs': 300,\n",
    "                                              'batch_size': 64,\n",
    "                                              'n_size': [256, 128, 64],\n",
    "                                              'seq_len': 100,\n",
    "                                              'n_bottleneck': 32,\n",
    "                                              'loss': 'mean_squared_error',\n",
    "                                              'callbacks': [\n",
    "                                                      tf.keras.callbacks.EarlyStopping(\n",
    "                                                        monitor='val_loss',\n",
    "                                                        patience=10,\n",
    "                                                        mode='min',\n",
    "                                                        start_from_epoch= 150,\n",
    "                                                        ),\n",
    "                                                 ]\n",
    "                                      }\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = os.name\n",
    "if platform == 'nt':\n",
    "    onedrive = Path(r'C:\\Users\\tomje\\OneDrive - Cardiff University')\n",
    "    onedrive = onedrive.joinpath('Documents', 'PHD', 'AE')\n",
    "    TB_DIR= onedrive.joinpath('Tensorboard')\n",
    "elif platform == 'posix':\n",
    "    onedrive = Path(r'/mnt/c/Users/tomje/OneDrive - Cardiff University')\n",
    "    onedrive = onedrive.joinpath('Documents', 'PHD', 'AE')\n",
    "    TB_DIR= onedrive.joinpath('Tensorboard')\n",
    "print(TB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add model checkpoint callback after creating model\n",
    "for test in exps:\n",
    "    name = autoe[test].run_name\n",
    "    model_folder = TB_DIR.joinpath(autoe[test]._tb_logdir.joinpath(name))\n",
    "    if not os.path.exists(model_folder):\n",
    "       os.makedirs(model_folder)\n",
    "    assert os.path.exists(model_folder)\n",
    "\n",
    "    autoe[test].model.callbacks.append(\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_folder.joinpath(f'{name}.h5'),\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train each autoe on the training data\n",
    "- `x` is the inputted data for training, which is `autoe.train_data`\n",
    "- `val_data` is the validation data from `autoe.val_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in exps:\n",
    "        autoe[test].fit(x=autoe[test].train_data,\n",
    "                        val_data=autoe[test].val_data,\n",
    "                        verbose=0,\n",
    "                        use_multiprocessing=True,\n",
    "                        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload saved weights from best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in exps:\n",
    "    name = autoe[test].run_name\n",
    "    model_folder = TB_DIR.joinpath(autoe[test]._tb_logdir.joinpath(name))\n",
    "    autoe[test].model.model_.load_weights(\n",
    "        TB_DIR.joinpath(model_folder.joinpath(f'{name}.h5'),),\n",
    "    )\n",
    "    autoe[test].pred = None\n",
    "    autoe[test].scores = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss plot of each trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(exps),\n",
    "                       figsize=(10,5),\n",
    "                       constrained_layout=True,\n",
    "                       )\n",
    "# ax = ax.ravel()\n",
    "for i, test in enumerate(exps):\n",
    "    axis = fig.axes[i]\n",
    "    autoe[test].loss_plot(plt_ax=axis)\n",
    "    axis.set_yscale('log')\n",
    "    if i > 0:\n",
    "        axis.set_ylabel('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score each model\n",
    "- Models scored on train, validation and whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in exps:\n",
    "    autoe[test].scores = None\n",
    "    autoe[test].pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in exps:\n",
    "    print(f'\\n {test}')\n",
    "    pred_tr, scores_tr = autoe[test].score('train')\n",
    "    pred_val, scores_val = autoe[test].score('val')\n",
    "    pred_data, scores_data = autoe[test].score('dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show histogram of scores across training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in exps:\n",
    "    fig, ax = autoe[test].hist_scores(['mse'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show model recreation capability of training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in exps:\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15,3), constrained_layout=True)\n",
    "    fig.suptitle(f'{autoe[test].RMS.exp_name} - Reconstruction')\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    # Training plot\n",
    "    ax[0] = autoe[test].pred_plot(autoe[test]._ind_tr[0], plt_ax=ax[0])\n",
    "    ax[0].set_title(f'Training Data - Cut {autoe[test]._ind_tr[0]} \\n{ax[0].get_title()}')\n",
    "\n",
    "    # Validation plot\n",
    "    ax[1] = autoe[test].pred_plot(autoe[test]._ind_val[0], plt_ax=ax[1])\n",
    "    ax[1].set_title(f'Val Data - Cut {autoe[test]._ind_val[0]} \\n{ax[1].get_title()}')\n",
    "\n",
    "    # Unseen plot\n",
    "    i = -100\n",
    "    ax[2] = autoe[test].pred_plot(i, input=(autoe[test].data, autoe[test].pred), plt_ax=ax[2])\n",
    "    ax[2].set_title(f'Unseen Data - Cut {i} \\n{ax[2].get_title()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholds for anomaly detection of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in exps:\n",
    "    autoe[test]._thres = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in exps:\n",
    "    autoe[test].thres"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show scores against threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = ['mse', 'mae', 'r2']\n",
    "metrics = ['mse', 'mae']\n",
    "\n",
    "fig, ax = plt.subplots(len(metrics), len(exps),\n",
    "                       figsize=(10, 5),\n",
    "                       constrained_layout=True,\n",
    "                    #    sharey= 'row',\n",
    "                       sharex='col',\n",
    "                       )\n",
    "axes = fig.axes\n",
    "\n",
    "for i, test in enumerate(exps):\n",
    "    for j, met in enumerate(metrics):\n",
    "        _ = autoe[test].scatter_scores([met], plt_ax=axes[(i + (j * len(exps)))])\n",
    "\n",
    "        axes[(i)].set_title(test)\n",
    "        axes[(len(exps) * j) + i].set_ylabel('')\n",
    "        axes[(len(exps) * j) + i].set_xlabel('')\n",
    "        if i == 0:\n",
    "            axes[(len(exps) * j) + i].set_ylabel(f'{met.upper()}')\n",
    "\n",
    "_ = fig.supxlabel('Cut Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['mse', 'mae']\n",
    "\n",
    "fig, ax = plt.subplots(len(metrics), len(exps),\n",
    "                       figsize=(10, 6),\n",
    "                       constrained_layout=True,\n",
    "                       sharex='col',\n",
    "                       dpi=500\n",
    "                       )\n",
    "axes = fig.axes\n",
    "\n",
    "for i, test in enumerate(exps):\n",
    "    for j, met in enumerate(metrics):\n",
    "        _ = autoe[test].scatter_scores([met], plt_ax=axes[(i + (j * len(exps)))])\n",
    "        # score = autoe[test].scores[met]\n",
    "        # axes[(i + (j * len(exps)))].scatter(x=range(len(score)),\n",
    "        #                                     y=score,\n",
    "        #                                     s=2,\n",
    "        #                                     label=met,\n",
    "        #                                     c='b'\n",
    "        #                                     )\n",
    "\n",
    "        axes[(len(exps) * j) + i].axvline(autoe[test]._train_slice.stop * 300,\n",
    "                                    color='k',\n",
    "                                    linestyle='--',\n",
    "                                    alpha=0.5,\n",
    "                                    )\n",
    "\n",
    "        axes[(i + (j * len(exps)))].axhline(autoe[test].thres[met], color='r', linestyle='--')\n",
    "\n",
    "        axes[(i)].set_title(f'Test {i+ 1}')\n",
    "        axes[(len(exps) * j) + i].set_ylabel('')\n",
    "        axes[(len(exps) * j) + i].set_xlabel('')\n",
    "        if i == 0:\n",
    "            axes[(len(exps) * j) + i].set_ylabel(f'{met.upper()}')\n",
    "\n",
    "_ = fig.supxlabel('Cut Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.DataFrame(autoe[test].scores) for test in exps]\n",
    "df = pd.concat(dfs, keys=exps, names=['Test', 'Metrics'])\n",
    "for test in exps:\n",
    "    print(f'\\n {test}')\n",
    "    print(df.loc[test].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoe models latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test in exps:\n",
    "#     fig, ax = autoe[test].plot_latent_space()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wear measurements comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = ['mse', 'mae']\n",
    "features = ['Runout', 'Form error']\n",
    "\n",
    "fig, ax = plt.subplots(len(metric), len(exps),\n",
    "                       figsize=(10, 6),\n",
    "                       constrained_layout=True,\n",
    "                    #    sharey= 'row',\n",
    "                       sharex='col',\n",
    "                       dpi=500,\n",
    "                       )\n",
    "\n",
    "ax2 = []\n",
    "\n",
    "try:\n",
    "    ax.ravel()\n",
    "    for a in ax.ravel():\n",
    "        ax2.append(a.twinx())\n",
    "except AttributeError:\n",
    "    ax2.append(ax.twinx())\n",
    "\n",
    "for a, b in zip(ax2[1:], ax2[0:-1]):\n",
    "    a.sharey(b)\n",
    "\n",
    "if len(metric) * len(exps) > 1:\n",
    "    ax2 = np.reshape(ax2, ax.shape)\n",
    "\n",
    "axes = fig.axes\n",
    "axes2 = axes[-(len(axes) // 2):]\n",
    "axes = axes[0:(len(axes) // 2)]\n",
    "for i, test in enumerate(exps):\n",
    "    axes[i].set_title(f'Test {i + 1}')\n",
    "    # axes[i].set_title(test)\n",
    "\n",
    "    exp = resources.load(test)\n",
    "    for j, met in enumerate(metric):\n",
    "        _ = autoe[test].scatter_scores([met], plt_ax=axes[(i + (j * len(exps)))])\n",
    "\n",
    "        # vert line to show where training data ends\n",
    "        axes[(len(exps) * j) + i].axvline(autoe[test]._train_slice.stop * 300,\n",
    "                                    color='k',\n",
    "                                    linestyle='--',\n",
    "                                    alpha=0.5,\n",
    "                                    )\n",
    "\n",
    "        for feature in features:\n",
    "            feat = exp.features[feature].drop([0, 1, 2])\n",
    "            if test == 'Test 5':\n",
    "                feat = feat.drop([23, 24])\n",
    "            # axes2[(len(exps) * j) + i].plot(range(len(feat)), feat, label=feature)\n",
    "            axes2[(len(exps) * j) + i].plot(range(0, len(autoe[test].scores[met]), 300), feat, label=feature)\n",
    "\n",
    "        axes[(len(exps) * j) + i].set_xlabel('')\n",
    "        axes[(len(exps) * j) + i].set_ylabel('')\n",
    "        if i == 0:\n",
    "            axes[(len(exps) * j) + i].set_ylabel(f'{met.upper()}')\n",
    "        if i ==len(exps) - 1:\n",
    "            axes2[(len(exps) * j) + i].set_ylabel('Errors')\n",
    "\n",
    "_ = fig.supxlabel('Cut Number')\n",
    "\n",
    "for i, a in enumerate(axes2):\n",
    "    if (i + 1) % len(exps) != 0:\n",
    "        plt.setp(a.get_yticklabels(), visible=False)\n",
    "\n",
    "l1, lab1 = axes[0].get_legend_handles_labels()\n",
    "l2, lab2 = axes2[0].get_legend_handles_labels()\n",
    "\n",
    "plt.figlegend(l1 + l2,\n",
    "              ['Metric'] + lab2, \n",
    "              loc='upper center', \n",
    "              bbox_to_anchor=(0.5, 0),\n",
    "              ncol=len(l1 + l2)\n",
    "              )\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in exps:\n",
    "    fig, ax = plt.subplots(figsize=(10, 4), dpi=200)\n",
    "    try:\n",
    "        autoe[test].anom_plot(anomaly_metric='mse', plt_ax=ax)\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1, len(exps), figsize=(10,5), constrained_layout=True)\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, test in enumerate(exps):\n",
    "    a = autoe[test]\n",
    "    sc = a.scores['mse'][a.ind_tr]\n",
    "\n",
    "    def mad_based_outlier(points, thresh=2):\n",
    "        if len(points.shape) == 1:\n",
    "            points = points[:,None]\n",
    "        median = np.median(points, axis=0)\n",
    "        diff = np.sum((points - median)**2, axis=-1)\n",
    "        diff = np.sqrt(diff)\n",
    "        med_abs_deviation = np.median(diff)\n",
    "\n",
    "        modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "        return modified_z_score > thresh\n",
    "\n",
    "    outliers = sc[mad_based_outlier(sc)]\n",
    "    print(np.min(outliers))\n",
    "\n",
    "    sns.histplot(sc, ax=ax[i], kde=True, log_scale=False, bins=50)\n",
    "    ax[i].plot(outliers, np.zeros_like(outliers), 'ro', clip_on=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
