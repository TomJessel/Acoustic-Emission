{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomje/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.ml_mlp import MLP_Model\n",
    "from src.ml_mlp import Linear_Model\n",
    "from src.ml_mlp import MLP_Win_Model\n",
    "from src.ml_mlp import LSTM_Model\n",
    "import src\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method(\"spawn\")\n",
    "from launch_tb import launch_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    # \"text.usetex\": True,\n",
    "    # \"font.family\": \"serif\",\n",
    "    # \"font.serif\": [\"Computer Modern Roman\"],\n",
    "    \"font.size\": 12,\n",
    "})\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-process data \n",
    "Load in feature datasets, remove wear in phase and combine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp5 = src.load('Test 5')\n",
    "exp7 = src.load('Test 7')\n",
    "exp8 = src.load('Test 8')\n",
    "exp9 = src.load('Test 9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [exp5.features.drop([23, 24]), exp7.features, exp8.features, exp9.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df.drop([0, 1, 2, 3]) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main df : 692 rows x 8 cols\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMS</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Freq 10 kHz</th>\n",
       "      <th>Freq 35 kHz</th>\n",
       "      <th>Freq 134 kHz</th>\n",
       "      <th>Mean radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.114074</td>\n",
       "      <td>7.972114</td>\n",
       "      <td>22.575564</td>\n",
       "      <td>-0.037290</td>\n",
       "      <td>46.668353</td>\n",
       "      <td>75.681806</td>\n",
       "      <td>42.884274</td>\n",
       "      <td>0.673830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.231453</td>\n",
       "      <td>7.937418</td>\n",
       "      <td>20.322581</td>\n",
       "      <td>-0.030997</td>\n",
       "      <td>47.223827</td>\n",
       "      <td>76.327768</td>\n",
       "      <td>43.081297</td>\n",
       "      <td>0.672418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218086</td>\n",
       "      <td>8.176863</td>\n",
       "      <td>21.918605</td>\n",
       "      <td>-0.013387</td>\n",
       "      <td>47.121927</td>\n",
       "      <td>76.566675</td>\n",
       "      <td>42.880229</td>\n",
       "      <td>0.672192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.288520</td>\n",
       "      <td>7.950098</td>\n",
       "      <td>19.731200</td>\n",
       "      <td>-0.023563</td>\n",
       "      <td>47.644657</td>\n",
       "      <td>76.725483</td>\n",
       "      <td>43.181154</td>\n",
       "      <td>0.672081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.297028</td>\n",
       "      <td>8.107973</td>\n",
       "      <td>22.351243</td>\n",
       "      <td>-0.014962</td>\n",
       "      <td>47.152297</td>\n",
       "      <td>76.585970</td>\n",
       "      <td>43.056571</td>\n",
       "      <td>0.671812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMS  Kurtosis  Amplitude  Skewness  Freq 10 kHz  Freq 35 kHz  \\\n",
       "0  2.114074  7.972114  22.575564 -0.037290    46.668353    75.681806   \n",
       "1  2.231453  7.937418  20.322581 -0.030997    47.223827    76.327768   \n",
       "2  2.218086  8.176863  21.918605 -0.013387    47.121927    76.566675   \n",
       "3  2.288520  7.950098  19.731200 -0.023563    47.644657    76.725483   \n",
       "4  2.297028  8.107973  22.351243 -0.014962    47.152297    76.585970   \n",
       "\n",
       "   Freq 134 kHz  Mean radius  \n",
       "0     42.884274     0.673830  \n",
       "1     43.081297     0.672418  \n",
       "2     42.880229     0.672192  \n",
       "3     43.181154     0.672081  \n",
       "4     43.056571     0.671812  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.concat(dfs)\n",
    "main_df = main_df.drop(columns=['Runout', 'Form error', 'Peak radius', 'Radius diff'])#.drop([0, 1, 2, 3])\n",
    "main_df.reset_index(drop=True, inplace=True)\n",
    "print(f'Main df : {main_df.shape[0]} rows x {main_df.shape[1]} cols')\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_plot(y: np.ndarray, y_pred: np.ndarray, title:str = ''):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    ax1.scatter(y, y_pred)\n",
    "\n",
    "    # limits of max radius\n",
    "    # xmax = main_df['Mean radius'].values.max()\n",
    "    # xmin = main_df['Mean radius'].values.min()\n",
    "    xmax = 0.68\n",
    "    xmin = 0.6\n",
    "    \n",
    "\n",
    "    ax1.set_xlim([xmin, xmax])\n",
    "    ax1.set_ylim([xmin, xmax])\n",
    "\n",
    "    lims = [\n",
    "        np.min([ax1.get_xlim(), ax1.get_ylim()]),\n",
    "        np.max([ax1.get_xlim(), ax1.get_ylim()]),\n",
    "    ]\n",
    "    ax1.set_axisbelow(True)\n",
    "    ax1.grid()\n",
    "    ax1.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.set_xlabel('Actual Y (mm)')\n",
    "    ax1.set_ylabel('Predicted Y (mm)')\n",
    "    ax1.set_title(f'{title} - Predictions');\n",
    "     \n",
    "    diff = (y - y_pred)*1000\n",
    "\n",
    "    ax2.hist(diff, bins=30)\n",
    "    ax2.set_xlabel('Prediction Error / um')\n",
    "    ax2.set_ylabel('No Occurances')\n",
    "    ax2.set_title(f'{title} - Histogram');\n",
    "\n",
    "    fig1.tight_layout()\n",
    "    fig2.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp_reg = MLP_Model(feature_df=main_df,\n",
    "                    target='Mean radius',\n",
    "                    tb=True,\n",
    "                    tb_logdir='loss_plot',\n",
    "                    params={'loss': 'mse',\n",
    "                            'no_layers': 3,\n",
    "                            'no_nodes': 128,\n",
    "                            'epochs': 1000,\n",
    "                            'dropout': 0.01,\n",
    "                            'batch_size': 64,\n",
    "                            'init_mode': 'glorot_uniform',\n",
    "                            'callbacks': [\n",
    "                                # tf.keras.callbacks.EarlyStopping(\n",
    "                                #     monitor='val_loss',\n",
    "                                #     patience=300,\n",
    "                                #     mode='min',\n",
    "                                #     start_from_epoch=250,\n",
    "                                # ),\n",
    "                                ]\n",
    "                            },\n",
    "                    random_state=2,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch_tb(f'MLP/tmux-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_reg.model.callbacks.append(\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'{mlp_reg._run_name}/{mlp_reg._run_name.split(mlp_reg.tb_log_dir)[1][1:]}.h5',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp_reg.cv(n_splits=10, n_repeats=10)\n",
    "mlp_reg.fit(validation_split=0.33, verbose=0)\n",
    "    # lstm_reg.model.model_.load_weights(lstm_reg._run_name + '.h5')\n",
    "# mlp_reg.model.model_.load_weights(f'{mlp_reg._run_name}/{mlp_reg._run_name.split(mlp_reg.tb_log_dir)[1][1:]}.h5')\n",
    "mlp_reg.score(plot_fig=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse_mlp = [scores['MSE'] for scores in mlp_reg.cvScores]\n",
    "plt.hist(cv_mse_mlp, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [l for l in mlp_reg.model.history_['loss']]\n",
    "val_loss = [l for l in mlp_reg.model.history_['val_loss']]\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.ylim([0, 5e-4])\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# y = mlp_reg.val_data[1].values\n",
    "# y_pred = mlp_reg.model.predict(mlp_reg.val_data[0].values, verbose=0)\n",
    "# pred_plot(y, y_pred, 'MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP with Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_win_reg = MLP_Win_Model(feature_df=main_df,\n",
    "                            target='Mean radius',\n",
    "                            tb=True,\n",
    "                            tb_logdir='loss_plot',\n",
    "                            params={'seq_len': 5,\n",
    "                                    'loss': 'mse',\n",
    "                                    'epochs': 1000,\n",
    "                                    'no_nodes': 128,\n",
    "                                    'no_layers': 4,\n",
    "                                    'batch_size': 64,\n",
    "                                    'init_mode': 'glorot_uniform',\n",
    "                                    'dropout': 0.01,\n",
    "                                    'callbacks': [\n",
    "                                        # tf.keras.callbacks.EarlyStopping(\n",
    "                                        #     monitor='val_loss',\n",
    "                                        #     patience=100,\n",
    "                                        #     mode='min',\n",
    "                                        #     start_from_epoch=200,\n",
    "                                        # ),\n",
    "                                        ]\n",
    "                                    },\n",
    "                            random_state=11,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_win_reg.model.callbacks.append(\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'{mlp_win_reg._run_name}/{mlp_win_reg._run_name.split(mlp_win_reg.tb_log_dir)[1][1:]}.h5',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp_win_reg.cv(n_splits=10, n_repeats=10)\n",
    "mlp_win_reg.fit(validation_split=0.2, verbose=0)\n",
    "# mlp_win_reg.model.model_.load_weights(f'{mlp_win_reg._run_name}/{mlp_win_reg._run_name.split(mlp_win_reg.tb_log_dir)[1][1:]}.h5')\n",
    "mlp_win_reg.score(plot_fig=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_mse_mlpwin = [scores['MSE'] for scores in mlp_win_reg.cvScores]\n",
    "plt.hist(cv_mse_mlpwin, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y = mlp_win_reg.val_data[1]\n",
    "# y_pred = mlp_win_reg.model.predict(mlp_win_reg.val_data[0], verbose=0)\n",
    "# pred_plot(y, y_pred, 'MLP_WIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [l for l in mlp_win_reg.model.history_['loss']]\n",
    "val_loss = [l for l in mlp_win_reg.model.history_['val_loss']]\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.ylim([0, 5e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "def dependent_ttest(data1, data2, alpha):\n",
    " # calculate means\n",
    " mean1, mean2 = np.mean(data1), np.mean(data2)\n",
    " # number of paired samples\n",
    " n = len(data1)\n",
    " # sum squared difference between observations\n",
    " d1 = sum([(data1[i]-data2[i])**2 for i in range(n)])\n",
    " # sum difference between observations\n",
    " d2 = sum([data1[i]-data2[i] for i in range(n)])\n",
    " # standard deviation of the difference between means\n",
    " sd = np.sqrt((d1 - (d2**2 / n)) / (n - 1))\n",
    " # standard error of the difference between the means\n",
    " sed = sd / np.sqrt(n)\n",
    " # calculate the t statistic\n",
    " t_stat = (mean1 - mean2) / sed\n",
    " # degrees of freedom\n",
    " df = n - 1\n",
    " # calculate the critical value\n",
    " cv = t.ppf(1.0 - alpha, df)\n",
    " # calculate the p-value\n",
    " p = (1.0 - t.cdf(abs(t_stat), df)) * 2.0\n",
    " # return everything\n",
    " return t_stat, df, cv, p\n",
    "\n",
    "alpha = 0.05\n",
    "t_stat, df, cv, p = dependent_ttest(cv_mse_mlp, cv_mse_mlpwin,alpha)\n",
    "print('t=%.3f, df=%d, cv=%.3f, p=%.3f' % (t_stat, df, cv, p))\n",
    "# interpret via critical value\n",
    "if abs(t_stat) <= cv:\n",
    " print('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    " print('Reject the null hypothesis that the means are equal.')\n",
    "# interpret via p-value\n",
    "if p > alpha:\n",
    " print('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    " print('Reject the null hypothesis that the means are equal.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_reg = LSTM_Model(feature_df=main_df,\n",
    "                      target='Mean radius',\n",
    "                      tb=True,\n",
    "                      tb_logdir='loss_plot',\n",
    "                      params={'seq_len': 15,\n",
    "                              'loss': 'mse',\n",
    "                              'epochs': 3000,\n",
    "                              'no_layers': 3,\n",
    "                              'no_dense': 2,\n",
    "                              'no_nodes': 64,\n",
    "                              'batch_size': 32,\n",
    "                              'init_mode': 'glorot_uniform',\n",
    "                              'dropout': 0.01,\n",
    "                              'callbacks': [\n",
    "                                        # tf.keras.callbacks.EarlyStopping(\n",
    "                                        #     monitor='val_loss',\n",
    "                                        #     patience=100,\n",
    "                                        #     mode='min',\n",
    "                                        #     start_from_epoch=500,\n",
    "                                        # ),\n",
    "                                        ]\n",
    "                              },\n",
    "                      random_state=11,\n",
    "                      shuffle=True,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_reg.model.callbacks.append(\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'{lstm_reg._run_name}/{lstm_reg._run_name.split(lstm_reg.tb_log_dir)[1][1:]}.h5',\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_reg.cv(n_splits=10, n_repeats=10)\n",
    "lstm_reg.fit(validation_split=0.2, verbose=0)\n",
    "lstm_reg.model.model_.load_weights(f'{lstm_reg._run_name}/{lstm_reg._run_name.split(lstm_reg.tb_log_dir)[1][1:]}.h5')\n",
    "lstm_reg.score(plot_fig=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = [l for l in lstm_reg.model.history_['loss']]\n",
    "val_loss = [l for l in lstm_reg.model.history_['val_loss']]\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.ylim([0, 5e-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = lstm_reg.val_data[1]\n",
    "# y_pred = lstm_reg.model.predict(lstm_reg.val_data[0], verbose=0)\n",
    "# pred_plot(y, y_pred, 'LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = Linear_Model(feature_df=main_df, target='Mean radius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [139, 553]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/tomje/python/Acoustic-Emission/ml/ml_testing.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tomje/python/Acoustic-Emission/ml/ml_testing.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m lin_reg\u001b[39m.\u001b[39mfit()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tomje/python/Acoustic-Emission/ml/ml_testing.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m lin_reg\u001b[39m.\u001b[39;49mscore(plot_fig\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m);\n",
      "File \u001b[0;32m~/python/Acoustic-Emission/resources/resources/ml_mlp.py:841\u001b[0m, in \u001b[0;36mLinear_Model.score\u001b[0;34m(self, model, X, y, plot_fig, print_score)\u001b[0m\n\u001b[1;32m    835\u001b[0m scoring \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mMAE\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mneg_mean_absolute_error\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    836\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mMSE\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    837\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[1;32m    839\u001b[0m cv \u001b[39m=\u001b[39m RepeatedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_repeats\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m--> 841\u001b[0m _test_score \u001b[39m=\u001b[39m cross_validate(estimator\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    842\u001b[0m                              X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    843\u001b[0m                              y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    844\u001b[0m                              scoring\u001b[39m=\u001b[39;49mscoring,\n\u001b[1;32m    845\u001b[0m                              cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    846\u001b[0m                              return_train_score\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    847\u001b[0m                              n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    848\u001b[0m                              )\n\u001b[1;32m    850\u001b[0m \u001b[39mif\u001b[39;00m print_score:\n\u001b[1;32m    851\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m65\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:252\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcross_validate\u001b[39m(\n\u001b[1;32m     50\u001b[0m     estimator,\n\u001b[1;32m     51\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m     error_score\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan,\n\u001b[1;32m     64\u001b[0m ):\n\u001b[1;32m     65\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39m    [0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m    254\u001b[0m     cv \u001b[39m=\u001b[39m check_cv(cv, y, classifier\u001b[39m=\u001b[39mis_classifier(estimator))\n\u001b[1;32m    256\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/utils/validation.py:433\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \n\u001b[1;32m    416\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    432\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[0;32m--> 433\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [139, 553]"
     ]
    }
   ],
   "source": [
    "lin_reg.fit()\n",
    "lin_reg.score(plot_fig=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/tomje/python/Acoustic-Emission/ml/ml_testing.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tomje/python/Acoustic-Emission/ml/ml_testing.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m y \u001b[39m=\u001b[39m lin_reg\u001b[39m.\u001b[39;49mval_data[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tomje/python/Acoustic-Emission/ml/ml_testing.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred \u001b[39m=\u001b[39m lin_reg\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(lin_reg\u001b[39m.\u001b[39mval_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tomje/python/Acoustic-Emission/ml/ml_testing.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m pred_plot(y, y_pred, \u001b[39m'\u001b[39m\u001b[39mLinear\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "y = lin_reg.val_data[1].values\n",
    "y_pred = lin_reg.model.predict(lin_reg.val_data[0].values)\n",
    "pred_plot(y, y_pred, 'Linear')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures for Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_real_plot(y, y_pred, ax):\n",
    "    ax.scatter(y, y_pred, marker='+', alpha=0.8, s=50)\n",
    "\n",
    "    xmax = 0.68\n",
    "    xmin = 0.6\n",
    "\n",
    "    ax.set_xlim([xmin, xmax])\n",
    "    ax.set_ylim([xmin, xmax])\n",
    "\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid()\n",
    "    ax.plot(lims, lims, 'k--', alpha=0.75, zorder=0, linewidth=1)\n",
    "    ax.set_aspect('equal')\n",
    "    return ax\n",
    "\n",
    "\n",
    "models = {'MLP': mlp_reg, \n",
    "          'MLP_WIN': mlp_win_reg, \n",
    "          'LSTM': lstm_reg\n",
    "          }\n",
    "\n",
    "y = {name: mod.val_data[1] for name, mod in models.items()}\n",
    "y_pred = {name: mod.model.predict(mod.val_data[0], verbose=0) for name, mod in models.items()}\n",
    "\n",
    "fig, ax = plt.subplots(1, len(models), figsize=(12, 5), sharey=True, dpi = 100)\n",
    "ax = ax.ravel()\n",
    "for i, m in enumerate(models):\n",
    "    ax[i] = pred_real_plot(y[str(m)], y_pred[str(m)], ax[i])\n",
    "    ax[i].set_title(str(m), fontsize=12)\n",
    "    ax[i].set_xlabel('Actual Y (mm)', fontsize=12)\n",
    "ax[0].set_ylabel('Predicted Y (mm)', fontsize=12)\n",
    "fig.tight_layout()\n",
    "\n",
    "y = {name: mod.train_data[1] for name, mod in models.items()}\n",
    "y_pred = {name: mod.model.predict(mod.train_data[0], verbose=0) for name, mod in models.items()}\n",
    "\n",
    "fig, ax = plt.subplots(1, len(models), figsize=(12, 5), sharey=True, dpi = 100)\n",
    "ax = ax.ravel()\n",
    "for i, m in enumerate(models):\n",
    "    ax[i] = pred_real_plot(y[str(m)], y_pred[str(m)], ax[i])\n",
    "    ax[i].set_title(str(m), fontsize=12)\n",
    "    ax[i].set_xlabel('Actual Y (mm)', fontsize=12)\n",
    "ax[0].set_ylabel('Predicted Y (mm)', fontsize=12)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show prediction of entire wear cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def sequence_data(d: np.ndarray, mod):\n",
    "    seq_data = []\n",
    "    seq_len = mod.seq_len\n",
    "    prev_points = deque(maxlen=seq_len)\n",
    "\n",
    "    for i in d:\n",
    "        prev_points.append([n for n in i])\n",
    "        if len(prev_points) == seq_len:\n",
    "            seq_data.append([np.array(prev_points)])\n",
    "    return seq_data\n",
    "\n",
    "\n",
    "dfs = [exp5.features.drop([23, 24]), exp7.features, exp8.features, exp9.features]\n",
    "\n",
    "fig, ax = plt.subplots(1, len(dfs), figsize=(15, 5), dpi = 300)\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "\n",
    "    df = df.drop(columns=['Runout', 'Form error', 'Peak radius', 'Radius diff']).drop([0, 1, 2, 3])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.head()\n",
    "\n",
    "    mods = {'MLP': mlp_reg,\n",
    "            'MLP_WIN': mlp_win_reg,\n",
    "            'LSTM': lstm_reg,\n",
    "            }\n",
    "\n",
    "    x = df.drop(columns=['Mean radius']).to_numpy()\n",
    "    y = df['Mean radius'].to_numpy()\n",
    "\n",
    "    x_mlp = mods['MLP'].scaler.transform(x)\n",
    "\n",
    "    x_mlp_win = sequence_data(mods['MLP_WIN'].scaler.transform(x), mods['MLP_WIN'])\n",
    "    x_mlp_win = np.asarray(x_mlp_win).reshape(len(x_mlp_win), mods['MLP_WIN']._no_features)\n",
    "\n",
    "    x_lstm = sequence_data(mods['LSTM'].scaler.transform(x), mods['LSTM'])\n",
    "    x_lstm = np.asarray(x_lstm).squeeze()\n",
    "\n",
    "    y_pred_mlp = mods['MLP'].model.predict(x_mlp, verbose=0)\n",
    "    y_pred_mlp_win = mods['MLP_WIN'].model.predict(x_mlp_win, verbose=0)\n",
    "    y_pred_lstm = mods['LSTM'].model.predict(x_lstm, verbose=0)\n",
    "\n",
    "    # print(f'Test {i + 1}')\n",
    "    # print('-' * 65)\n",
    "    # print('\\tMLP')\n",
    "    # mods['MLP'].score(X=x_mlp, y=y, plot_fig=False)\n",
    "    # print('-' * 65)\n",
    "    # print('\\tMLP_WIN')\n",
    "    # mods['MLP_WIN'].score(X=x_mlp_win, y=y[-len(x_mlp_win):], plot_fig=False)\n",
    "    # print('-' * 65)\n",
    "    # print('\\tLSTM')\n",
    "    # mods['LSTM'].score(X=x_lstm, y=y[-len(x_lstm):], plot_fig=False)\n",
    "    # print('\\n')\n",
    "\n",
    "    mlp_win_slen = mods['MLP_WIN'].seq_len\n",
    "    lstm_slen = mods['LSTM'].seq_len\n",
    "\n",
    "    ax[i].plot(y, label='Actual')\n",
    "    ax[i].plot(y_pred_mlp, label='MLP')\n",
    "    ax[i].plot(np.insert(y_pred_mlp_win, 0, [np.NaN] * (mlp_win_slen - 1)) , label='MLP_WIN')\n",
    "    ax[i].plot(np.insert(y_pred_lstm, 0, [np.NaN] * (lstm_slen - 1)), label='LSTM')\n",
    "    ax[i].legend(fontsize=8)\n",
    "    ax[i].set_xlabel('Cut No.')\n",
    "    ax[i].set_title(f'Test {i+1}')\n",
    "    ax[i].autoscale(enable=True, axis='x', tight=True)\n",
    "\n",
    "ax[0].set_ylabel('Mean radius (mm)')\n",
    "fig.tight_layout()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# pred_real_plot(y[-len(y_pred_lstm):], y_pred_lstm, ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train MLP models on all but one Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import deque\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# def sequence_data(d: np.ndarray, mod):\n",
    "#     seq_data = []\n",
    "#     seq_len = mod.seq_len\n",
    "#     prev_points = deque(maxlen=seq_len)\n",
    "\n",
    "#     for i in d:\n",
    "#         prev_points.append([n for n in i])\n",
    "#         if len(prev_points) == seq_len:\n",
    "#             seq_data.append([np.array(prev_points)])\n",
    "#     return seq_data\n",
    "\n",
    "# mod = lstm_reg\n",
    "# for i, val_df in enumerate(dfs):\n",
    "#     tr_df = dfs[:i] + dfs[i + 1:]\n",
    "#     tr_df = pd.concat(tr_df)\n",
    "#     tr_df = tr_df.drop(columns=['Runout', 'Form error', 'Peak radius', 'Radius diff'])\n",
    "#     tr_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#     mod.main_df = tr_df\n",
    "#     mod.pre_process(val_frac=0.1)\n",
    "#     mod.fit(verbose=0)\n",
    "#     mod.score(plot_fig=False)\n",
    "\n",
    "#     val_df = val_df.drop(columns=['Runout', 'Form error', 'Peak radius', 'Radius diff'])\n",
    "#     val_x = val_df.drop(columns=['Mean radius']).to_numpy()\n",
    "#     val_x = sequence_data(mod.scaler.transform(x), mod)\n",
    "#     val_x = np.asarray(val_x).squeeze()\n",
    "#     val_y = val_df['Mean radius'].to_numpy()\n",
    "    \n",
    "#     val_pred = mod.model.predict(val_x, verbose=0)\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(val_y, label='Actual')\n",
    "#     ax.plot(np.insert(val_pred, 0, [np.NaN] * (mod.seq_len - 1)), label='Predicted')\n",
    "#     ax.legend(fontsize=8)\n",
    "#     ax.set_xlabel('Cut No.')\n",
    "#     ax.set_ylabel('Mean radius (mm)')\n",
    "#     ax.set_title(f'Val data {i+1}')\n",
    "#     ax.autoscale(enable=True, axis='x', tight=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "a77c530f20afcac94425b35af8d25e3592d4e6fc3ab5e13da56c5d55af5be430"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
